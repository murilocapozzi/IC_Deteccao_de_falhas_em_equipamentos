{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Detecção de falhas em equipamentos por meio de inspeção visual\n",
        "\n",
        "Iniciação científica voluntária\n",
        "\n",
        "Murilo Capozzi dos Santos\n",
        "\n",
        "Orientadora: Profa. Dra. Lilian Berton\n",
        "\n",
        "Instituto de Ciência e Tecnologia - UNIFESP\n",
        "\n",
        "murilo.capozzi@unifesp.br"
      ],
      "metadata": {
        "id": "zvscMfsNro-6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAxkPn4UnT-3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHzDIm_67b21"
      },
      "source": [
        "Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLJ6dEmRgBpy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "import keras.utils as image\n",
        "from keras.utils import load_img\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras.backend as K\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.efficientnet import EfficientNetB0\n",
        "from keras.api._v2.keras import Model\n",
        "\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dhLWlev7u-nv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliação Holdout"
      ],
      "metadata": {
        "id": "vWVZkjh2u_m6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER_Olkx88x_R"
      },
      "outputs": [],
      "source": [
        "img_shape = [200, 200, 3]\n",
        "base_directory = '/content/drive/MyDrive/IC/NEU-DET'\n",
        "\n",
        "train_path = base_directory + '/train'\n",
        "test_path = base_directory + '/test'\n",
        "val_path = base_directory + '/validation'\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "gen_train = ImageDataGenerator(rescale=1./255,\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=True,\n",
        "                               zoom_range=0.1,\n",
        "                               brightness_range=[0.9,1.0])\n",
        "\n",
        "base_train = gen_train.flow_from_directory(train_path,\n",
        "                                           target_size=(200, 200),\n",
        "                                           batch_size=batch_size,\n",
        "                                           class_mode='categorical',\n",
        "                                           shuffle=True)\n",
        "\n",
        "gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_test = gen_val.flow_from_directory(val_path,\n",
        "                                       target_size=(200, 200),\n",
        "                                       batch_size=batch_size,\n",
        "                                       class_mode='categorical',\n",
        "                                       shuffle=False)\n",
        "\n",
        "gen_test = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "base_test = gen_test.flow_from_directory(test_path,\n",
        "                                         target_size=(200, 200),\n",
        "                                         batch_size=batch_size,\n",
        "                                         class_mode='categorical',\n",
        "                                         shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJenu_9XXcum"
      },
      "outputs": [],
      "source": [
        "def grafico(model_history, model_name):\n",
        "\n",
        "  history = model_history\n",
        "\n",
        "  acc = history.history['categorical_accuracy']\n",
        "  val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.plot(acc, label='Training Accuracy')\n",
        "  plt.plot(val_acc, label='Validation Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.ylim([min(plt.ylim()),1])\n",
        "  plt.title(model_name + ' - Training and Validation Accuracy')\n",
        "\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.plot(loss, label='Training Loss')\n",
        "  plt.plot(val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.ylabel('Cross Entropy')\n",
        "  plt.ylim([0,1.0])\n",
        "  plt.title(model_name + ' - Training and Validation Loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfWSJxOk4YXm"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, base, model_name):\n",
        "  pred = model.predict(base)\n",
        "\n",
        "  test_loss, test_accuracy = model.evaluate(base, batch_size=batch_size)\n",
        "\n",
        "  print()\n",
        "  print(f\"Test Loss:     {test_loss}\")\n",
        "  print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "  y_pred = np.argmax(pred, axis=1)\n",
        "  y_true = base.classes\n",
        "\n",
        "  print(classification_report(y_true, y_pred))\n",
        "\n",
        "  cf_mtx = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "  group_counts = [\"{0:0.0f}\".format(value) for value in cf_mtx.flatten()]\n",
        "  group_percentages = [\"{0:.2%}\".format(value) for value in cf_mtx.flatten()/np.sum(cf_mtx)]\n",
        "  box_labels = [f\"{v1}\\n({v2})\" for v1, v2 in zip(group_counts, group_percentages)]\n",
        "  box_labels = np.asarray(box_labels).reshape(6, 6)\n",
        "\n",
        "  plt.figure(figsize = (12, 10))\n",
        "  sns.heatmap(cf_mtx, xticklabels=base.class_indices.values(), yticklabels=base.class_indices.values(),\n",
        "            cmap=\"YlGnBu\", fmt=\"\", annot=box_labels)\n",
        "  plt.xlabel('Predicted Classes')\n",
        "  plt.ylabel('True Classes')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEzyKUHz7RUp"
      },
      "source": [
        "Treinamento customizado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nBPaqvt-eDM"
      },
      "outputs": [],
      "source": [
        "rede_neural = Sequential()\n",
        "\n",
        "rede_neural.add(Conv2D(filters=16, kernel_size=(3,3), input_shape=img_shape, activation='relu', padding='same'))\n",
        "rede_neural.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "rede_neural.add(BatchNormalization())\n",
        "\n",
        "rede_neural.add(Conv2D(filters=8, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "rede_neural.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "rede_neural.add(BatchNormalization())\n",
        "\n",
        "rede_neural.add(Flatten(input_shape=img_shape))\n",
        "\n",
        "rede_neural.add(Dense(units=64, activation='relu'))\n",
        "rede_neural.add(Dropout(rate=0.3))\n",
        "rede_neural.add(Dense(units=6, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HDNUXRG_lsd"
      },
      "outputs": [],
      "source": [
        "rede_neural.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                    metrics = ['categorical_accuracy'])\n",
        "\n",
        "history_n = rede_neural.fit(base_train,\n",
        "                            epochs=1,\n",
        "                            validation_data=val_test)\n",
        "\n",
        "grafico(history_n, 'Rede Neural')\n",
        "\n",
        "evaluate(rede_neural, base_test, 'Rede Neural')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMBRJWDSPeV-"
      },
      "source": [
        "MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQrBg8VN6DKz"
      },
      "outputs": [],
      "source": [
        "base_model = MobileNetV2(input_shape=img_shape,\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "fine_tune_at = 153\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(6, activation='softmax')\n",
        "\n",
        "inputs = tf.keras.Input(shape=img_shape)\n",
        "x = base_model(inputs, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "outputs = prediction_layer(x)\n",
        "model_mobile = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyxwfmTVePT0"
      },
      "outputs": [],
      "source": [
        "model_mobile.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                    metrics = ['categorical_accuracy'])\n",
        "history_mobilenet = model_mobile.fit(base_train,\n",
        "                                     epochs=100,\n",
        "                                     validation_data=val_test)\n",
        "\n",
        "grafico(history_mobilenet, 'MobileNetV2')\n",
        "\n",
        "evaluate(model_mobile, base_test, 'MobileNetV2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R02XQo9AlNEv"
      },
      "source": [
        "ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c83MJcx5kSSr"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet50(input_shape=img_shape,\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "fine_tune_at = 173\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(6, activation='softmax')\n",
        "\n",
        "inputs = tf.keras.Input(shape=img_shape)\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "#x = keras.applications.resnet_v2.preprocess_input(x)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model_resnet = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet.compile(optimizer=tf.keras.optimizers.Adam(1e-2),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                    metrics = ['categorical_accuracy'])\n",
        "\n",
        "history_resnet = model_resnet.fit(base_train,\n",
        "                                  epochs=100,\n",
        "                                  validation_data=val_test)\n",
        "\n",
        "grafico(history_resnet, 'ResNet50')\n",
        "\n",
        "evaluate(model_resnet, base_test, 'ResNet50')"
      ],
      "metadata": {
        "id": "o5RbtKPZt-b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKKf6F4dlQp3"
      },
      "source": [
        "VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyDzvVHtCIk2"
      },
      "outputs": [],
      "source": [
        "base_model = VGG16(input_shape=img_shape,\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "fine_tune_at = 18\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(6, activation='softmax')\n",
        "\n",
        "inputs = tf.keras.Input(shape=img_shape)\n",
        "x = base_model(inputs, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model_vgg = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_vgg.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWOWVnYsCXc6"
      },
      "outputs": [],
      "source": [
        "model_vgg.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                    metrics = ['categorical_accuracy'])\n",
        "\n",
        "history_vgg = model_vgg.fit(base_train,\n",
        "                            epochs=100,\n",
        "                            validation_data=val_test)\n",
        "\n",
        "grafico(history_vgg, 'VGG16')\n",
        "\n",
        "evaluate(model_vgg, base_test, 'VGG16')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6qGj9eGlRuz"
      },
      "source": [
        "Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuDgCvW0CcrV"
      },
      "outputs": [],
      "source": [
        "base_model = Xception(input_shape=img_shape,\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "base_model.trainable = True\n",
        "\n",
        "fine_tune_at = 130\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(6, activation='softmax')\n",
        "\n",
        "inputs = tf.keras.Input(shape=img_shape)\n",
        "x = base_model(inputs, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model_xception = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8KLMdm8ZyCL"
      },
      "outputs": [],
      "source": [
        "model_xception.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                    metrics = ['categorical_accuracy'])\n",
        "\n",
        "history_xception = model_xception.fit(base_train,\n",
        "                            epochs=100,\n",
        "                            validation_data=val_test)\n",
        "\n",
        "grafico(history_xception, 'Xception')\n",
        "\n",
        "evaluate(model_xception, base_train, 'Xception')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4ZmAyLglS5n"
      },
      "source": [
        "InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rB4LybEVCm_U"
      },
      "outputs": [],
      "source": [
        "base_model = InceptionV3(input_shape=img_shape,\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "fine_tune_at = 309\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(6, activation='softmax')\n",
        "\n",
        "inputs = tf.keras.Input(shape=img_shape)\n",
        "x = base_model(inputs, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model_inception = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vZYsmvsZ5yp"
      },
      "outputs": [],
      "source": [
        "model_inception.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                    metrics = ['categorical_accuracy'])\n",
        "\n",
        "antes = time.time()\n",
        "history_inception = model_inception.fit(base_train,\n",
        "                                    epochs=100,\n",
        "                                    validation_data=val_test)\n",
        "depois = time.time()\n",
        "print(\"\\nInception demorou {0:.6f}\".format(depois-antes) + \" segundos\")\n",
        "\n",
        "grafico(history_inception, 'InceptionV3')\n",
        "\n",
        "evaluate(model_inception, base_test, 'InceptionV3')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qaIX_90YtJs2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliação KFold"
      ],
      "metadata": {
        "id": "XYMhdYmytFJo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoZYWarWDTCH",
        "outputId": "03a8f0b1-19bc-426e-cb6f-c08be56cbb35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1620 images belonging to 6 classes.\n",
            "Found 180 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "img_shape = [200, 200, 3]\n",
        "base_directory = '/content/drive/MyDrive/IC/NEU-DET_KFold'\n",
        "\n",
        "train_path = base_directory + '/train'\n",
        "val_path = base_directory + '/validation'\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "gen_train = ImageDataGenerator(rescale=1./255,\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=True,\n",
        "                               zoom_range=0.1,\n",
        "                               brightness_range=[0.9,1.0])\n",
        "\n",
        "base_train = gen_train.flow_from_directory(train_path,\n",
        "                                           target_size=(200, 200),\n",
        "                                           batch_size=batch_size,\n",
        "                                           class_mode='categorical',\n",
        "                                           shuffle=False)\n",
        "\n",
        "gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "base_val = gen_val.flow_from_directory(val_path,\n",
        "                                         target_size=(200, 200),\n",
        "                                         batch_size=batch_size,\n",
        "                                         class_mode='categorical',\n",
        "                                         shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF0fwvWcNMkM"
      },
      "outputs": [],
      "source": [
        "def grafico_folds(model_history_acc, model_history_loss, nfolds, model_name):\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.ylim([min(plt.ylim()),1])\n",
        "  plt.title(model_name + ' - Training Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.ylabel('Accuracy')\n",
        "\n",
        "  for i in range(nfolds):\n",
        "    acc = model_history_acc[i]\n",
        "\n",
        "    lbl = 'Fold ' + str(i+1)\n",
        "\n",
        "    plt.plot(acc, label=lbl)\n",
        "\n",
        "  plt.legend(['Fold 1','Fold 2','Fold 3','Fold 4','Fold 5'])\n",
        "\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.ylabel('Cross Entropy')\n",
        "  plt.title(model_name + ' - Training Loss')\n",
        "  plt.ylim([0,1.0])\n",
        "\n",
        "  for i in range(nfolds):\n",
        "    loss = model_history_loss[i]\n",
        "\n",
        "    lbl = 'Fold ' + str(i+1)\n",
        "\n",
        "    plt.plot(loss, label=lbl)\n",
        "\n",
        "\n",
        "  plt.legend(['Fold 1','Fold 2','Fold 3','Fold 4','Fold 5'])\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF3_O-lXHBl9"
      },
      "outputs": [],
      "source": [
        "def evaluate_folds(model, base, model_name, fold):\n",
        "  pred = model.predict(base)\n",
        "\n",
        "  test_loss, test_accuracy = model.evaluate(base, batch_size=batch_size)\n",
        "\n",
        "  print()\n",
        "  print(f\"Test Loss:     {test_loss}\")\n",
        "  print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "  y_pred = np.argmax(pred, axis=1)\n",
        "  y_true = base.classes\n",
        "\n",
        "  print(classification_report(y_true, y_pred, zero_division=0))\n",
        "\n",
        "  cf_mtx = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "  group_counts = [\"{0:0.0f}\".format(value) for value in cf_mtx.flatten()]\n",
        "  group_percentages = [\"{0:.2%}\".format(value) for value in cf_mtx.flatten()/np.sum(cf_mtx)]\n",
        "  box_labels = [f\"{v1}\\n({v2})\" for v1, v2 in zip(group_counts, group_percentages)]\n",
        "  box_labels = np.asarray(box_labels).reshape(6, 6)\n",
        "\n",
        "  plt.figure(figsize = (12, 10))\n",
        "  sns.heatmap(cf_mtx, xticklabels=base.class_indices.values(), yticklabels=base.class_indices.values(),\n",
        "            cmap=\"YlGnBu\", fmt=\"\", annot=box_labels)\n",
        "  plt.xlabel('Predicted Classes')\n",
        "  plt.ylabel('True Classes')\n",
        "  plt.title(model_name + ' - Fold ' + str(fold+1))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwoHlyoDDJN7"
      },
      "outputs": [],
      "source": [
        "def create_rede():\n",
        "  rede_neural = Sequential()\n",
        "\n",
        "  rede_neural.add(Conv2D(filters=16, kernel_size=(3,3), input_shape=img_shape, activation='relu', padding='same'))\n",
        "  rede_neural.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "  rede_neural.add(BatchNormalization())\n",
        "\n",
        "  rede_neural.add(Conv2D(filters=8, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "  rede_neural.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "  rede_neural.add(BatchNormalization())\n",
        "\n",
        "  rede_neural.add(Flatten(input_shape=img_shape))\n",
        "\n",
        "  rede_neural.add(Dense(units=64, activation='relu'))\n",
        "  rede_neural.add(Dropout(rate=0.3))\n",
        "  rede_neural.add(Dense(units=6, activation='softmax'))\n",
        "\n",
        "  rede_neural.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
        "                      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                      metrics = ['categorical_accuracy'])\n",
        "\n",
        "  return rede_neural\n",
        "\n",
        "\n",
        "def create_mobile():\n",
        "  base_model = MobileNetV2(input_shape=img_shape,\n",
        "                          include_top=False,\n",
        "                          weights='imagenet')\n",
        "\n",
        "  base_model.trainable = True\n",
        "\n",
        "  fine_tune_at = 153\n",
        "\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "  prediction_layer = tf.keras.layers.Dense(6, activation='softmax')\n",
        "\n",
        "  inputs = tf.keras.Input(shape=img_shape)\n",
        "  x = base_model(inputs, training=False)\n",
        "  x = global_average_layer(x)\n",
        "  x = tf.keras.layers.Dropout(0.3)(x)\n",
        "  outputs = prediction_layer(x)\n",
        "  model_mobile = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  model_mobile.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                    metrics = ['categorical_accuracy'])\n",
        "\n",
        "  return model_mobile\n",
        "\n",
        "def create_resnet():\n",
        "  base_model = ResNet50(input_shape=img_shape,\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "\n",
        "  base_model.trainable = True\n",
        "\n",
        "  fine_tune_at = 173\n",
        "\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "  prediction_layer = tf.keras.layers.Dense(6, activation='softmax')\n",
        "\n",
        "  inputs = tf.keras.Input(shape=img_shape)\n",
        "\n",
        "  x = base_model(inputs, training=False)\n",
        "  x = keras.applications.resnet_v2.preprocess_input(x)\n",
        "  x = global_average_layer(x)\n",
        "  x = tf.keras.layers.Dropout(0.3)(x)\n",
        "  outputs = prediction_layer(x)\n",
        "  model_resnet = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  model_resnet.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                    metrics = ['categorical_accuracy'])\n",
        "\n",
        "  return model_resnet\n",
        "\n",
        "def create_vgg():\n",
        "  base_model = VGG16(input_shape=img_shape,\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "\n",
        "  base_model.trainable = True\n",
        "\n",
        "  fine_tune_at = 18\n",
        "\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "  prediction_layer = tf.keras.layers.Dense(6, activation='softmax')\n",
        "\n",
        "  inputs = tf.keras.Input(shape=img_shape)\n",
        "  x = base_model(inputs, training=False)\n",
        "  x = global_average_layer(x)\n",
        "  x = tf.keras.layers.Dropout(0.3)(x)\n",
        "  outputs = prediction_layer(x)\n",
        "  model_vgg = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  model_vgg.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                    metrics = ['categorical_accuracy'])\n",
        "\n",
        "  return model_vgg\n",
        "\n",
        "def create_xception():\n",
        "  base_model = Xception(input_shape=img_shape,\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "\n",
        "  base_model.trainable = True\n",
        "\n",
        "  fine_tune_at = 130\n",
        "\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "  prediction_layer = tf.keras.layers.Dense(6, activation='softmax')\n",
        "\n",
        "  inputs = tf.keras.Input(shape=img_shape)\n",
        "  x = base_model(inputs, training=False)\n",
        "  x = global_average_layer(x)\n",
        "  x = tf.keras.layers.Dropout(0.3)(x)\n",
        "  outputs = prediction_layer(x)\n",
        "  model_xception = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  model_xception.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                    metrics = ['categorical_accuracy'])\n",
        "\n",
        "  return model_xception\n",
        "\n",
        "def create_inception():\n",
        "  base_model = InceptionV3(input_shape=img_shape,\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "\n",
        "  base_model.trainable = True\n",
        "\n",
        "  fine_tune_at = 309\n",
        "\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "  prediction_layer = tf.keras.layers.Dense(6, activation='softmax')\n",
        "\n",
        "  inputs = tf.keras.Input(shape=img_shape)\n",
        "  x = base_model(inputs, training=False)\n",
        "  x = global_average_layer(x)\n",
        "  x = tf.keras.layers.Dropout(0.3)(x)\n",
        "  outputs = prediction_layer(x)\n",
        "  model_inception = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  model_inception.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                    metrics = ['categorical_accuracy'])\n",
        "\n",
        "  return model_inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LaemvJIrvDqb"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "n_folds = 5\n",
        "\n",
        "x = np.concatenate([base_train.next()[0] for i in range(base_train.__len__())])\n",
        "y = np.concatenate([base_train.next()[1] for i in range(base_train.__len__())])\n",
        "\n",
        "\n",
        "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
        "\n",
        "dict = {\n",
        "    \"Rede Neural\" : create_rede,\n",
        "    \"MobileNetV2\": create_mobile,\n",
        "    \"ResNet50\" : create_resnet,\n",
        "    \"VGG16\" : create_vgg,\n",
        "    \"Xception\" : create_xception,\n",
        "    \"InceptionV3\" : create_inception,\n",
        "}\n",
        "\n",
        "models = [\"Rede Neural\", \"MobileNetV2\", \"ResNet50\", \"VGG16\", \"Xception\", \"InceptionV3\"]\n",
        "\n",
        "for model_name in models:\n",
        "\n",
        "  history_acc = [None for i in range(n_folds)]\n",
        "  history_loss = [None for i in range(n_folds)]\n",
        "\n",
        "  for i, (train, test) in enumerate(kfold.split(x, y.argmax(1))):\n",
        "\n",
        "    model = dict[model_name]()\n",
        "\n",
        "    history = model.fit(x[train], y[train], epochs=100, verbose=0)\n",
        "    scores = model.evaluate(x[test], y[test], verbose=0)\n",
        "\n",
        "    print(f'Score for fold {i+1}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    history_acc[i] = history.history['categorical_accuracy']\n",
        "    history_loss[i] = history.history['loss']\n",
        "\n",
        "    evaluate_folds(model, base_val, model_name, i)\n",
        "\n",
        "  grafico_folds(history_acc, history_loss, n_folds, model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kpkN3-2RvL33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grad-CAM"
      ],
      "metadata": {
        "id": "9Y3AbTPovNyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img_array(img_path, size):\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, base_model, model, last_conv_layer_name, classifier_layer_names):\n",
        "    last_conv_layer = base_model.get_layer(last_conv_layer_name)\n",
        "    last_conv_layer_model = keras.Model(base_model.inputs, last_conv_layer.output)\n",
        "\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    for layer_name in classifier_layer_names:\n",
        "        x = model.get_layer(layer_name)(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap\n",
        "\n",
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
        "    img = keras.utils.load_img(img_path)\n",
        "    img = keras.utils.img_to_array(img)\n",
        "\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    jet = plt.colormaps[\"jet\"]\n",
        "\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
        "\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
        "\n",
        "    superimposed_img.save(cam_path)\n",
        "\n",
        "    display(Image(cam_path))"
      ],
      "metadata": {
        "id": "YaZVv1nxvMiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    print(layer.name)\n",
        "\n",
        "base_model = model.layers[1]\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  print(layer.name)\n",
        "\n",
        "last_conv_layer_name = 'out_relu'\n",
        "preprocess_input = keras.applications.mobilenet_v2.preprocess_input\n",
        "decode_predictions = keras.applications.mobilenet_v2.decode_predictions\n",
        "\n",
        "classifier_layer_names = [layer.name for layer in model.layers]\n",
        "del classifier_layer_names[1]\n",
        "\n",
        "print(classifier_layer_names)\n",
        "\n",
        "heatmaps = []\n",
        "\n",
        "for _ in range(base_test.__len__()):\n",
        "  for img in base_test.next()[0]:\n",
        "    np.insert(img, 0, None)\n",
        "    heatmap = make_gradcam_heatmap(tf.expand_dims(img,axis=0), base_model, model, last_conv_layer_name, classifier_layer_names)\n",
        "    heatmaps.append(heatmap)\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmaps[0])\n",
        "plt.show()\n",
        "\n",
        "dict = {\n",
        "    \"Pitted Surface\": '/content/drive/MyDrive/IC/NEU-DET/test/pitted_surface/pitted_surface_300.jpg',\n",
        "    \"Patches\": '/content/drive/MyDrive/IC/NEU-DET/test/patches/patches_300.jpg',\n",
        "    \"Scratches\": '/content/drive/MyDrive/IC/NEU-DET/test/scratches/scratches_300.jpg',\n",
        "    \"Rolled-in Scale\": '/content/drive/MyDrive/IC/NEU-DET/test/rolled-in_scale/rolled-in_scale_300.jpg',\n",
        "    \"Crazing\": '/content/drive/MyDrive/IC/NEU-DET/test/crazing/crazing_300.jpg',\n",
        "    \"Inclusion\": '/content/drive/MyDrive/IC/NEU-DET/test/inclusion/inclusion_300.jpg'\n",
        "}\n",
        "images = [\"Pitted Surface\", \"Patches\", \"Scratches\", \"Rolled-in Scale\", \"Crazing\",\"Inclusion\"]\n",
        "\n",
        "for img, heatmap in zip(images, heatmaps):\n",
        "  img_path = dict[img]\n",
        "  print(img)\n",
        "  display(Image(img_path))\n",
        "  save_and_display_gradcam(img_path, heatmap)"
      ],
      "metadata": {
        "id": "6UsFliWlvU7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bqzYQNIxvTpw"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}